worker_processes auto;
worker_rlimit_nofile 65535;

events {
    worker_connections 8192;
    multi_accept on;
    use epoll;
}

http {
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    # Disable access logs for perf, keep only critical errors
    access_log off;
    error_log /var/log/nginx/error.log crit;

    # Upstream to Phoenix apps (could be multiple containers)
    upstream phoenix {
        server api:4000 max_fails=3 fail_timeout=30s;
        # server app2:4000; # add more nodes here if scaling horizontally
        keepalive 128;
    }

    server {
        listen 9999 reuseport;
        server_name _;

        location / {
            proxy_pass http://phoenix;
            proxy_http_version 1.1;

            # Forward headers
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "";
            proxy_set_header Host $host;

            # Timeouts
            proxy_connect_timeout 5s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;

            # Avoid extra buffering (pass through directly)
            proxy_buffering off;
            proxy_request_buffering off;
        }

        location /nginx_status {
            stub_status;
            allow 127.0.0.1;
            allow 172.16.0.0/12;   
            deny all;
        }
    }
}



# worker_processes auto;
# # worker_processes 4;
# events {
#     worker_connections  1024000;    # How many simultaneous connections a worker can handle
#     multi_accept        on;      # Accept as many connections as possible at once
#     use epoll;                   # Best for Linux (scalable event loop)
# }

# http {

#     tcp_nopush      on;           # Send headers in one packet
#     tcp_nodelay     on;           # Low-latency requests (important for APIs)

#     # keepalive_timeout 30;
#     # keepalive_requests 1000;
#     # default is 65;
#     # server will close connection after this time (in seconds)

#     gzip on;
#     gzip_vary on;                  # Adds Vary: Accept-Encoding header
#     gzip_proxied any;               # Compress even for proxied requests
#     gzip_comp_level 6;              # Compression level (CPU-friendly)
#     gzip_buffers 16 8k;             # Buffer size for compression
#     gzip_http_version 1.1;          # Only compress for HTTP/1.1+
#     gzip_min_length 256;            # Skip tiny responses
#     gzip_types text/plain application/json text/css application/javascript text/html;

#     # reduces the data that needs to be sent over the network

#     # Limit logs if container stdout is too chatty

#     # log_format custom '$remote_addr - $remote_user [$time_local] "$request" '
#     #               '$status $body_bytes_sent "$http_referer" "$http_user_agent" '
#     #               '$request_time cache_status="$upstream_cache_status"';

#     log_format upstream_timing '$remote_addr - $remote_user [$time_local] '
#                            '"$request" $status $request_time '
#                            'connect:$upstream_connect_time '
#                            'header:$upstream_header_time '
#                            'response:$upstream_response_time '
#                            'status:$upstream_status';

#     # log_format custom '[$time_local] "$request" $status $request_time $upstream_response_time $upstream_status';

#     access_log /var/log/nginx/access.log upstream_timing;

#     # access_log  /var/log/nginx/access.log custom;
#     # access_log off;
#     # to boost I/O on HDD we can disable access logs
#     # this prevent nginx from logging every action in a log file named `access.log`.

#     error_log /var/log/nginx/error.log debug;

#     upstream api {
#         least_conn;
#         server api:4000;
#     }
#     server {
#         listen 9999;
        
#         location / {
#             proxy_pass http://api;
#             proxy_http_version 1.1;
#             proxy_set_header Connection "";
#             proxy_set_header Host $host;
#             proxy_set_header X-Real-IP $remote_addr;
#             proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

#         }

#         location /nginx_status {
#             stub_status;
#             allow 127.0.0.1;
#             allow 172.16.0.0/12;   
#             deny all;
#         }
#     }
# }

# # worker_processes 1;
# # worker_rlimit_nofile 500000;

# # events {
# #     use epoll;
# #     worker_connections 20480;
# # }
# # http {

# #      # Define cache storage
# #     proxy_cache_path /tmp/nginx_cache
# #         levels=1:2
# #         keys_zone=api_cache:50m   # cache metadata (index), ~8k keys per MB
# #         max_size=512m             # max total cache size
# #         inactive=10m              # drop entries not used for 10m
# #         use_temp_path=off;

# #     # log_format custom '$remote_addr - $remote_user [$time_local] '
# #     #               '"$request" $status $body_bytes_sent '
# #     #               '"$http_referer" "$http_user_agent" '
# #     #               '$request_time $upstream_response_time '
# #     #               '$upstream_status cache_status="$upstream_cache_status"';

# #     log_format upstream_timing '$remote_addr - $remote_user [$time_local] '
# #                            '"$request" $status $request_time '
# #                            'connect:$upstream_connect_time '
# #                            'header:$upstream_header_time '
# #                            'response:$upstream_response_time '
# #                            'status:$upstream_status';

# #     # log_format custom '[$time_local] "$request" $status $request_time $upstream_response_time $upstream_status';

# #     # access_log /var/log/nginx/access.log upstream_timing;


# #     access_log off;
# #     # error_log /dev/null emerg;
# #     error_log /var/log/nginx/error.log debug;

# #     upstream api {
# #         server api:3000;
# #         keepalive 200;
# #     }
# #     server {
# #         listen 9999;
# #         location / {
# #             proxy_buffering off;
# #             proxy_set_header Connection "";
# #             proxy_http_version 1.1;
# #             proxy_set_header Keep-Alive "";
# #             proxy_set_header Proxy-Connection "keep-alive";
# #             proxy_pass http://api;

# #             # proxy_connect_timeout   5s;   # time to establish TCP connection to upstream
# #             # proxy_send_timeout     60s;   # time to send request to upstream
# #             # proxy_read_timeout     60s;   # time to wait for response
# #             # send_timeout           60s;   # time to send response to client

# #             proxy_cache api_cache;
# #             proxy_cache_key "$scheme$request_method$host$request_uri";
# #             proxy_cache_valid 200 1m;   # cache 200 OK for 1 minute
# #             proxy_cache_valid 302 30s;  # optional: cache redirects briefly
# #             proxy_cache_valid 400 5m;            # cache "Bad Request" responses for 5 minutes
# #             # proxy_cache_min_uses 3;     # only cache after 3 identical requests

# #             # Don't cache POST, PUT, DELETE, etc.
# #             proxy_cache_methods GET HEAD;

# #             # Debug header: see HIT, MISS, BYPASS
# #             add_header X-Cache-Status $upstream_cache_status;
# #         }
# #     }
# # }